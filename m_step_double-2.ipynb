{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a9dbe5b-c63e-4c20-b71d-ae06edb34869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "# import seaborn as sns\n",
    "from numpy import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import original_data\n",
    "import optuna\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# config\n",
    "LEARNING_RATE = 0.0003\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "N_FRAME = 12\n",
    "TIME_LENGTH = 12\n",
    "N_SAMPLE = 10000\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "PATH_1 = './data/timedt.dataHe1.300'\n",
    "PATH_2 = './data/timedt.dataHe2.300'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0a8b4db2-6359-4b80-8581-519e31439785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_data(\n",
    "   path:str\n",
    "):\n",
    "    \"\"\"\n",
    "    input temperature : 温度\n",
    "    \n",
    "    return t, msd, csp, xyz, r_, v_xyz, v_, angle, g\n",
    "\n",
    "    t       时间序列(单位:ps)\n",
    "    msd     单He的msd(均方位移)\n",
    "    csp     CSP(中心对称参数)\n",
    "    xyz     单He的xyz坐标\n",
    "    r_      单He离原点距离\n",
    "    v_xyz   单He的沿xyz坐标的速度分量\n",
    "    v_      单He的速度大小\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as fin:\n",
    "        t = []      # 时间序列(单位:ps)\n",
    "        msd = []    # 单He的msd(均方位移)\n",
    "        csp = []    # CSP(中心对称参数)\n",
    "        xyz = []    # 单He的xyz坐标\n",
    "        r_ = []     # 单He离原点距离\n",
    "        v_xyz = []  # 单He的沿xyz坐标的速度分量\n",
    "        v_ = []     # 单He的速度大小\n",
    "        for i, line in enumerate(fin.readlines()[1:]):\n",
    "            data = list(map(float, line.strip().split(' ')))\n",
    "            t.append(data[0])\n",
    "            msd.append(data[1])\n",
    "            csp.append(data[2:8])\n",
    "            xyz.append(data[8:11])\n",
    "            r_.append(data[11])\n",
    "            v_xyz.append(data[12:15])\n",
    "            v_.append(data[15])\n",
    "\n",
    "    # with open(G_PATH.format(Temperature=temperature), 'r', encoding='utf-8') as fin:\n",
    "    #     g = []      # g参数\n",
    "    #     for i, line in enumerate(fin.readlines()[1:]):\n",
    "    #         data = list(map(float, line.strip().split(' ')))\n",
    "    #         g.append(data[1:7])\n",
    "    indices_to_remove = np.arange(1001, len(t) - 1, 1001)\n",
    "    t = np.array(t)\n",
    "    t = np.delete(t, indices_to_remove)\n",
    "    t = t.reshape(-1, 1)\n",
    "    msd = np.array(msd)\n",
    "    msd = np.delete(msd, indices_to_remove)\n",
    "    msd = msd.reshape(-1, 1)\n",
    "    csp = np.array(csp)\n",
    "    csp = np.delete(csp, indices_to_remove, axis=0)\n",
    "    xyz = np.array(xyz)\n",
    "    xyz = np.delete(xyz, indices_to_remove, axis=0)\n",
    "    r_ = np.sqrt(np.array(r_))\n",
    "    r_ = np.delete(r_, indices_to_remove)\n",
    "    r_ = r_.reshape(-1, 1)\n",
    "    v_xyz = np.array(v_xyz)\n",
    "    v_xyz = np.delete(v_xyz, indices_to_remove, axis=0)\n",
    "    v_ = np.sqrt(np.array(v_))\n",
    "    v_ = np.delete(v_, indices_to_remove)\n",
    "    v_ = v_.reshape(-1, 1)\n",
    "    angle = np.arccos(v_xyz / v_.reshape(len(t), 1))\n",
    "    # g = np.array(g)\n",
    "\n",
    "    return t, msd, csp, xyz, r_, v_xyz, v_, angle# , g\n",
    "# TRAIN\n",
    "def train(\n",
    "    net:nn.Module, \n",
    "    Train_generator, \n",
    "    loss_func,\n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    device\n",
    "):\n",
    "    net = net.to(device)\n",
    "    net.train()\n",
    "    sum_loss = []\n",
    "    \n",
    "    Train_generator =  DataLoader(Train_generator.dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "    for x, y in Train_generator:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        scores = net(x)\n",
    "        loss = loss_func(scores, y)\n",
    "        sum_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    return np.array(sum_loss).mean()\n",
    "    \n",
    "def evaluate(\n",
    "    net:nn.Module, \n",
    "    Test_generator, \n",
    "    loss_func,\n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    device\n",
    "):\n",
    "    sum_loss = []\n",
    "    net.eval()\n",
    "    Test_generator = DataLoader(Test_generator.dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "    for x, y in Test_generator:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        scores = net(x)\n",
    "        loss = loss_func(scores, y)\n",
    "        sum_loss.append(loss.item())\n",
    "    \n",
    "    return np.array(sum_loss).mean()\n",
    "\n",
    "\n",
    "def train_multi_epochs(\n",
    "    path, \n",
    "    net:nn.Module, \n",
    "    Train_generator, \n",
    "    Test_generator,     \n",
    "    loss_func,\n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    epochs, \n",
    "    device, \n",
    "    information:str, \n",
    "    show_train_process=None\n",
    "):\n",
    "    best_epoch = 0\n",
    "    best_test_loss = 9.9e9\n",
    "    best_net = net.state_dict()\n",
    "    sum_train_loss, sum_test_loss = [], []\n",
    "    date0 = time.strftime('%Y-%m-%d %a %H-%M-%S', time.localtime(time.time()))\n",
    "\n",
    "    with open(path.format(date=date0, information=information), 'w') as log_fin:\n",
    "        log_fin.write(information + '\\n')\n",
    "        log_fin.write('epoch' + ' ' + 'train_loss' + ' ' + 'test_loss' + ' ' + 'time' + ' ' + 'best_epoch' + '\\n')\n",
    "        t1 = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            t0 = time.time()\n",
    "            train_loss = train(net, Train_generator, loss_func, optimizer, scheduler, device).item()\n",
    "            test_loss = evaluate(net, Test_generator, loss_func, optimizer, scheduler, device).item()\n",
    "\n",
    "            sum_train_loss.append(train_loss)\n",
    "            sum_test_loss.append(test_loss)\n",
    "\n",
    "            if epoch == 0 or test_loss < best_test_loss:\n",
    "                best_epoch = epoch\n",
    "                best_test_loss = test_loss\n",
    "                best_net = net.state_dict()\n",
    "\n",
    "            log_fin.write(str(epoch) + ' ' + str(train_loss) + ' ' + str(test_loss) + ' ' + str(time.time()-t0) + ' ' + str(best_epoch) + '\\n')\n",
    "            if show_train_process != None and epoch % show_train_process == 0:\n",
    "                print('epoch={:>4}, train_loss= {:.4f}, test_loss= {:.4f}, time= {:.2f}sec, best_epoch= {:>4}'.format(epoch, train_loss, test_loss, time.time()-t1, best_epoch))\n",
    "                t1 = time.time()\n",
    "        \n",
    "        log_fin.write('\\n')\n",
    "        log_fin.write('best_epoch=' + str(best_epoch) + '\\n')\n",
    "        log_fin.write('best_test_loss=' + str(best_test_loss) + '\\n')\n",
    "    return best_test_loss, best_epoch, best_net, sum_train_loss, sum_test_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5870f37-f375-4829-a5f6-7fd12311a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iter(path1, path2,  Batch_size):\n",
    "    '''\n",
    "    这个index有没有用另外说\n",
    "    '''\n",
    "    data1 = get_original_data(path1)\n",
    "    data2 = get_original_data(path2)\n",
    "    y = np.hstack([data1[3][:,0].reshape(-1,1),data2[3][:,0].reshape(-1,1)])\n",
    "    # print([data1[3][:,0],data2[3][:,0]])\n",
    "    # index = np.where(label[TIME_LENGTH//2 : -TIME_LENGTH//2])[0] + TIME_LENGTH//2\n",
    "    data_num = int(len(data1[0])/TIME_LENGTH)\n",
    "    # print(len(range(TIME_LENGTH//2, len(data1[0])-TIME_LENGTH//2, TIME_LENGTH)))\n",
    "    # print(data_num)\n",
    "    data1 = np.hstack(data1)\n",
    "    data2 = np.hstack(data2)\n",
    "    data = np.hstack((data1[:,1:], data2[:,1:]))\n",
    "    INPUT_SIZE = data.shape[-1]\n",
    "    scaler = StandardScaler()\n",
    "    #data = scaler.fit_transform(data)\n",
    "    data_X = torch.from_numpy(data)\n",
    "    # print(data_X.shape)\n",
    "    data_Y = torch.from_numpy(y)\n",
    "    data_Y = data_Y\n",
    "    \n",
    "    X = torch.zeros(data_num, TIME_LENGTH//2, INPUT_SIZE)\n",
    "    Y = torch.zeros(data_num, TIME_LENGTH//2, 2)\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    # start_index = TIME_LENGTH // 2\n",
    "    # end_index = data_num - TIME_LENGTH // 2\n",
    "    # sample_indices = random.sample(range(start_index, end_index), N_SAMPLE)\n",
    "    # data_num = N_SAMPLE\n",
    "    \n",
    "    i=0\n",
    "    # for i, idx in enumerate(sample_indices):\n",
    "    for idx in range(TIME_LENGTH//2, N_SAMPLE-TIME_LENGTH//2, TIME_LENGTH):\n",
    "        X[i, :, :] = data_X[idx-TIME_LENGTH//2 : idx]\n",
    "        Y[i, :, :]    = data_Y[idx:idx+TIME_LENGTH//2]\n",
    "        i+=1\n",
    "\n",
    "    X = X.float().unsqueeze(1) # [Batch_size, C, H, W]\n",
    "    shuffled_index = np.random.permutation(range(data_num))\n",
    "    X = X[shuffled_index]\n",
    "    Y = Y[shuffled_index]\n",
    "    Y = Y.view(Y.size(0), -1)\n",
    "    Train_X, Test_X = X[:int(data_num*0.8)], X[int(data_num*0.8):]\n",
    "    Train_Y, Test_Y = Y[:int(data_num*0.8)], Y[int(data_num*0.8):]\n",
    "\n",
    "\n",
    "    Train_generator = DataLoader(\n",
    "        torch.utils.data.TensorDataset(Train_X, Train_Y), \n",
    "        Batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    Test_generator = DataLoader(\n",
    "        torch.utils.data.TensorDataset(Test_X, Test_Y), \n",
    "        Batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    return Train_generator, Test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bd5285b6-02ad-4c0d-bb8f-387d92a02b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        Channel_in, \n",
    "        Height_in, \n",
    "        Width_in, \n",
    "        Output_size, \n",
    "        Filter_num, \n",
    "        Kernel_list, \n",
    "        dropout = 0.5, \n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    Channel_in, \n",
    "                    Filter_num, \n",
    "                    kernel_size=(kernel, Width_in), \n",
    "                    padding=((kernel - 1) // 2, 0), \n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(\n",
    "                    kernel_size=((Height_in+3)//4, 1), \n",
    "                    stride=(Height_in+3)//4, \n",
    "                    padding=((Height_in-Height_in//4*4+1)//2, 0), \n",
    "                ), \n",
    "            )\n",
    "            for kernel in Kernel_list\n",
    "        ])\n",
    "        # print(Kernel_list)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout), \n",
    "            nn.Linear(Filter_num * len(Kernel_list) * 4, 64),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 16), \n",
    "            nn.Linear(16, Output_size)\n",
    "        )\n",
    "        # one -hot 时就这样就行 output_size=4\n",
    "        # self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        out = [conv(x) for conv in self.convs]\n",
    "        out = torch.cat(out, dim=1)\n",
    "        out = out.view(x.size(0), -1)\n",
    "        # print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        # output = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0cef23b3-473f-490d-baf0-218775e76b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n",
    "def singal_train_CNN(i, lr=LEARNING_RATE, ga=0.5, dropout=0.5):\n",
    "    t1 = time.time()\n",
    "    train_iter, test_iter = get_iter(PATH_1,PATH_2, BATCH_SIZE)\n",
    "    # test_iter = DataLoader([final_data, final_labels], batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "    # criteon = nn.BCEWithLogitsLoss().to(DEVICE)\n",
    "    criteon = nn.SmoothL1Loss().to(DEVICE)\n",
    "    # net = CNN(1, TIME_LENGTH, INPUT_SIZE, 1, 32, [3, 5, 7, 9], dropout)\n",
    "    net = CNN(1,TIME_LENGTH//2 , 18 * 2,TIME_LENGTH//2 * 2, 8, [9,7,5,3], dropout)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay=0)\n",
    "    scheduler = MultiStepLR(optimizer, [int(EPOCHS*0.2), int(EPOCHS*0.4)], ga, last_epoch=-1)\n",
    "\n",
    "    best_test_loss, best_epoch, _, multi_train_loss, multi_test_loss = train_multi_epochs(f'./output/{i}', net, train_iter, test_iter, criteon, optimizer, scheduler, EPOCHS, DEVICE, 'Temperature={}'.format(300), show_train_process=10)\n",
    "\n",
    "    print('best_test_loss= {:.4f}, best_epoch= {:>4}, time= {:.2f}sec'.format(best_test_loss, best_epoch, time.time()-t1))\n",
    "\n",
    "    plt.plot(multi_train_loss)\n",
    "    plt.plot(multi_test_loss)\n",
    "    plt.savefig(f'./output/{i}.png')\n",
    "    \n",
    "    return multi_train_loss, multi_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0ab0610c-c931-4e0d-b25b-844103d9fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记得差一下x y最后是不是空的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7649e-1b0a-4083-bfaa-4d1517e4211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=   0, train_loss= 0.0263, test_loss= 0.0110, time= 12.51sec, best_epoch=    0\n"
     ]
    }
   ],
   "source": [
    "multi_train_loss, multi_test_loss = singal_train_CNN(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3657f3aa-9329-4fff-bf7a-57b4e4896a39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
