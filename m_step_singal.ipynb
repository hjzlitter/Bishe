{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a9dbe5b-c63e-4c20-b71d-ae06edb34869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "# import seaborn as sns\n",
    "from numpy import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# import original_data\n",
    "import optuna\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# config\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 400\n",
    "N_FRAME = 12\n",
    "TIME_LENGTH = 12\n",
    "N_SAMPLE = 10000\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "PATH = './data/timedt.dataHe1.300'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0a8b4db2-6359-4b80-8581-519e31439785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_data(\n",
    "   path:str\n",
    "):\n",
    "    \"\"\"\n",
    "    input temperature : 温度\n",
    "    \n",
    "    return t, msd, csp, xyz, r_, v_xyz, v_, angle, g\n",
    "\n",
    "    t       时间序列(单位:ps)\n",
    "    msd     单He的msd(均方位移)\n",
    "    csp     CSP(中心对称参数)\n",
    "    xyz     单He的xyz坐标\n",
    "    r_      单He离原点距离\n",
    "    v_xyz   单He的沿xyz坐标的速度分量\n",
    "    v_      单He的速度大小\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as fin:\n",
    "        t = []      # 时间序列(单位:ps)\n",
    "        msd = []    # 单He的msd(均方位移)\n",
    "        csp = []    # CSP(中心对称参数)\n",
    "        xyz = []    # 单He的xyz坐标\n",
    "        r_ = []     # 单He离原点距离\n",
    "        v_xyz = []  # 单He的沿xyz坐标的速度分量\n",
    "        v_ = []     # 单He的速度大小\n",
    "        for i, line in enumerate(fin.readlines()[1:]):\n",
    "            data = list(map(float, line.strip().split(' ')))\n",
    "            t.append(data[0])\n",
    "            msd.append(data[1])\n",
    "            csp.append(data[2:8])\n",
    "            xyz.append(data[8:11])\n",
    "            r_.append(data[11])\n",
    "            v_xyz.append(data[12:15])\n",
    "            v_.append(data[15])\n",
    "\n",
    "    # with open(G_PATH.format(Temperature=temperature), 'r', encoding='utf-8') as fin:\n",
    "    #     g = []      # g参数\n",
    "    #     for i, line in enumerate(fin.readlines()[1:]):\n",
    "    #         data = list(map(float, line.strip().split(' ')))\n",
    "    #         g.append(data[1:7])\n",
    "    indices_to_remove = np.arange(1001, len(t) - 1, 1001)\n",
    "    t = np.array(t)\n",
    "    t = np.delete(t, indices_to_remove)\n",
    "    t = t.reshape(-1, 1)\n",
    "    msd = np.array(msd)\n",
    "    msd = np.delete(msd, indices_to_remove)\n",
    "    msd = msd.reshape(-1, 1)\n",
    "    csp = np.array(csp)\n",
    "    csp = np.delete(csp, indices_to_remove, axis=0)\n",
    "    xyz = np.array(xyz)\n",
    "    xyz = np.delete(xyz, indices_to_remove, axis=0)\n",
    "    r_ = np.sqrt(np.array(r_))\n",
    "    r_ = np.delete(r_, indices_to_remove)\n",
    "    r_ = r_.reshape(-1, 1)\n",
    "    v_xyz = np.array(v_xyz)\n",
    "    v_xyz = np.delete(v_xyz, indices_to_remove, axis=0)\n",
    "    v_ = np.sqrt(np.array(v_))\n",
    "    v_ = np.delete(v_, indices_to_remove)\n",
    "    v_ = v_.reshape(-1, 1)\n",
    "    angle = np.arccos(v_xyz / v_.reshape(len(t), 1))\n",
    "    # g = np.array(g)\n",
    "\n",
    "    return t, msd, csp, xyz, r_, v_xyz, v_, angle# , g\n",
    "# MODEL\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        Channel_in, \n",
    "        Height_in, \n",
    "        Width_in, \n",
    "        Output_size, \n",
    "        Filter_num, \n",
    "        Kernel_list, \n",
    "        dropout = 0.5, \n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    Channel_in, \n",
    "                    Filter_num, \n",
    "                    kernel_size=(kernel, Width_in), \n",
    "                    padding=((kernel - 1) // 2, 0), \n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(\n",
    "                    kernel_size=((Height_in+3)//4, 1), \n",
    "                    stride=(Height_in+3)//4, \n",
    "                    padding=((Height_in-Height_in//4*4+1)//2, 0), \n",
    "                ), \n",
    "            )\n",
    "            for kernel in Kernel_list\n",
    "        ])\n",
    "        # print(Kernel_list)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout), \n",
    "            nn.Linear(Filter_num * len(Kernel_list) * 4, 64),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 16), \n",
    "            nn.Linear(16, Output_size)\n",
    "        )\n",
    "        # one -hot 时就这样就行 output_size=4\n",
    "        # self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = [conv(x) for conv in self.convs]\n",
    "        out = torch.cat(out, dim=1)\n",
    "        out = out.view(x.size(0), -1)\n",
    "        # print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        # output = self.output(out)\n",
    "        return out\n",
    "\n",
    "# TRAIN\n",
    "def train(\n",
    "    net:nn.Module, \n",
    "    Train_generator, \n",
    "    loss_func,\n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    device\n",
    "):\n",
    "    net = net.to(device)\n",
    "    net.train()\n",
    "    sum_loss = []\n",
    "    \n",
    "    Train_generator =  DataLoader(Train_generator.dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "    for x, y in Train_generator:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        scores = net(x)\n",
    "        loss = loss_func(scores, y)\n",
    "        sum_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    return np.array(sum_loss).mean()\n",
    "    \n",
    "def evaluate(\n",
    "    net:nn.Module, \n",
    "    Test_generator, \n",
    "    loss_func,\n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    device\n",
    "):\n",
    "    sum_loss = []\n",
    "    net.eval()\n",
    "    Test_generator = DataLoader(Test_generator.dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "    for x, y in Test_generator:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        scores = net(x)\n",
    "        loss = loss_func(scores, y)\n",
    "        sum_loss.append(loss.item())\n",
    "    \n",
    "    return np.array(sum_loss).mean()\n",
    "\n",
    "\n",
    "def train_multi_epochs(\n",
    "    path, \n",
    "    net:nn.Module, \n",
    "    Train_generator, \n",
    "    Test_generator,     \n",
    "    loss_func,\n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    epochs, \n",
    "    device, \n",
    "    information:str, \n",
    "    show_train_process=None\n",
    "):\n",
    "    best_epoch = 0\n",
    "    best_test_loss = 9.9e9\n",
    "    best_net = net.state_dict()\n",
    "    sum_train_loss, sum_test_loss = [], []\n",
    "    date0 = time.strftime('%Y-%m-%d %a %H-%M-%S', time.localtime(time.time()))\n",
    "\n",
    "    with open(path.format(date=date0, information=information), 'w') as log_fin:\n",
    "        log_fin.write(information + '\\n')\n",
    "        log_fin.write('epoch' + ' ' + 'train_loss' + ' ' + 'test_loss' + ' ' + 'time' + ' ' + 'best_epoch' + '\\n')\n",
    "        t1 = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            t0 = time.time()\n",
    "            train_loss = train(net, Train_generator, loss_func, optimizer, scheduler, device).item()\n",
    "            test_loss = evaluate(net, Test_generator, loss_func, optimizer, scheduler, device).item()\n",
    "\n",
    "            sum_train_loss.append(train_loss)\n",
    "            sum_test_loss.append(test_loss)\n",
    "\n",
    "            if epoch == 0 or test_loss < best_test_loss:\n",
    "                best_epoch = epoch\n",
    "                best_test_loss = test_loss\n",
    "                best_net = net.state_dict()\n",
    "\n",
    "            log_fin.write(str(epoch) + ' ' + str(train_loss) + ' ' + str(test_loss) + ' ' + str(time.time()-t0) + ' ' + str(best_epoch) + '\\n')\n",
    "            if show_train_process != None and epoch % show_train_process == 0:\n",
    "                print('epoch={:>4}, train_loss= {:.4f}, test_loss= {:.4f}, time= {:.2f}sec, best_epoch= {:>4}'.format(epoch, train_loss, test_loss, time.time()-t1, best_epoch))\n",
    "                t1 = time.time()\n",
    "        \n",
    "        log_fin.write('\\n')\n",
    "        log_fin.write('best_epoch=' + str(best_epoch) + '\\n')\n",
    "        log_fin.write('best_test_loss=' + str(best_test_loss) + '\\n')\n",
    "    return best_test_loss, best_epoch, best_net, sum_train_loss, sum_test_loss\n",
    "\n",
    "\n",
    "def singal_train_CNN(i, lr=LEARNING_RATE, ga=0.5, dropout=0.5):\n",
    "    t1 = time.time()\n",
    "    # train_iter, test_iter = get_train_iter(TEMPERATURE, BATCH_SIZE)\n",
    "    train_iter = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_iter = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # test_iter = DataLoader([final_data, final_labels], batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "    # criteon = nn.BCEWithLogitsLoss().to(DEVICE)\n",
    "    criteon = nn.CrossEntropyLoss().to(DEVICE)\n",
    "    # net = CNN(1, TIME_LENGTH, INPUT_SIZE, 1, 32, [3, 5, 7, 9], dropout)\n",
    "    net = CNN(1,N_FRAME, 37,4, 8, [9,7,5,3], dropout)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay=0)\n",
    "    scheduler = MultiStepLR(optimizer, [int(EPOCHS*0.2), int(EPOCHS*0.4)], ga, last_epoch=-1)\n",
    "\n",
    "    best_test_loss, best_epoch, _, multi_train_loss, multi_test_loss = train_multi_epochs(f'./output/{i}', net, train_iter, test_iter, criteon, optimizer, scheduler, EPOCHS, DEVICE, 'Temperature={}'.format(300), show_train_process=10)\n",
    "\n",
    "    print('best_test_loss= {:.4f}, best_epoch= {:>4}, time= {:.2f}sec'.format(best_test_loss, best_epoch, time.time()-t1))\n",
    "\n",
    "    # plt.plot(multi_train_loss)\n",
    "    # plt.plot(multi_test_loss)\n",
    "    # plt.savefig(f'./output/{i}.png')\n",
    "    \n",
    "    return multi_train_loss, multi_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d5870f37-f375-4829-a5f6-7fd12311a148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iter(path, batch_size):\n",
    "    '''\n",
    "    这个index有没有用另外说\n",
    "    '''\n",
    "    data = get_original_data(path)\n",
    "    # index = np.where(label[TIME_LENGTH//2 : -TIME_LENGTH//2])[0] + TIME_LENGTH//2\n",
    "    data_num = len(data[0])\n",
    "\n",
    "    y = data[1]\n",
    "    data = np.hstack(data[1:])\n",
    "    INPUT_SIZE = data.shape[-1]\n",
    "    scaler = StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "    data_X = torch.from_numpy(data)\n",
    "    # print(data_X.shape)\n",
    "    data_Y = torch.from_numpy(y)\n",
    "    data_Y = data_Y.squeeze(1)\n",
    "    \n",
    "    X = torch.zeros(N_SAMPLE, TIME_LENGTH//2, INPUT_SIZE)\n",
    "    Y = torch.zeros(N_SAMPLE, TIME_LENGTH//2)\n",
    "    \n",
    "    import random\n",
    "    start_index = TIME_LENGTH // 2\n",
    "    end_index = data_num - TIME_LENGTH // 2\n",
    "    sample_indices = random.sample(range(start_index, end_index), N_SAMPLE)\n",
    "    data_num = N_SAMPLE\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        X[i, :, :] = data_X[idx-TIME_LENGTH//2 : idx]\n",
    "        Y[i, :]    = data_Y[idx:idx+TIME_LENGTH//2]\n",
    "\n",
    "    X = X.float().unsqueeze(1) # [Batch_size, C, H, W]\n",
    "    shuffled_index = np.random.permutation(range(data_num))\n",
    "    X = X[shuffled_index]\n",
    "    Y = Y[shuffled_index]\n",
    "    Train_X, Test_X = X[:int(data_num*0.8)], X[int(data_num*0.8):]\n",
    "    Train_Y, Test_Y = Y[:int(data_num*0.8)], Y[int(data_num*0.8):]\n",
    "\n",
    "\n",
    "    Train_generator = DataLoader(\n",
    "        torch.utils.data.TensorDataset(Train_X, Train_Y), \n",
    "        Batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    Test_generator = DataLoader(\n",
    "        torch.utils.data.TensorDataset(Test_X, Test_Y), \n",
    "        Batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    return Train_generator, Test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd5285b6-02ad-4c0d-bb8f-387d92a02b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        Channel_in, \n",
    "        Height_in, \n",
    "        Width_in, \n",
    "        Output_size, \n",
    "        Filter_num, \n",
    "        Kernel_list, \n",
    "        dropout = 0.5, \n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    Channel_in, \n",
    "                    Filter_num, \n",
    "                    kernel_size=(kernel, Width_in), \n",
    "                    padding=((kernel - 1) // 2, 0), \n",
    "                ),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(\n",
    "                    kernel_size=((Height_in+3)//4, 1), \n",
    "                    stride=(Height_in+3)//4, \n",
    "                    padding=((Height_in-Height_in//4*4+1)//2, 0), \n",
    "                ), \n",
    "            )\n",
    "            for kernel in Kernel_list\n",
    "        ])\n",
    "        # print(Kernel_list)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout), \n",
    "            nn.Linear(Filter_num * len(Kernel_list) * 4, 64),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 16), \n",
    "            nn.Linear(16, Output_size)\n",
    "        )\n",
    "        # one -hot 时就这样就行 output_size=4\n",
    "        # self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = [conv(x) for conv in self.convs]\n",
    "        out = torch.cat(out, dim=1)\n",
    "        out = out.view(x.size(0), -1)\n",
    "        # print(out.shape)\n",
    "        out = self.fc(out)\n",
    "        # output = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0cef23b3-473f-490d-baf0-218775e76b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    net:nn.Module, \n",
    "    Train_generator, \n",
    "    loss_func,\n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    device\n",
    "):\n",
    "    net = net.to(device)\n",
    "    net.train()\n",
    "    sum_loss = []\n",
    "    \n",
    "    Train_generator =  DataLoader(Train_generator.dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "    for x, y in Train_generator:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        scores = net(x)\n",
    "        loss = loss_func(scores, y)\n",
    "        sum_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    return np.array(sum_loss).mean()\n",
    "    \n",
    "def evaluate(\n",
    "    net:nn.Module, \n",
    "    Test_generator, \n",
    "    loss_func,\n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    device\n",
    "):\n",
    "    sum_loss = []\n",
    "    net.eval()\n",
    "    Test_generator = DataLoader(Test_generator.dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "    for x, y in Test_generator:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        scores = net(x)\n",
    "        loss = loss_func(scores, y)\n",
    "        sum_loss.append(loss.item())\n",
    "    \n",
    "    return np.array(sum_loss).mean()\n",
    "\n",
    "\n",
    "def train_multi_epochs(\n",
    "    path, \n",
    "    net:nn.Module, \n",
    "    Train_generator, \n",
    "    Test_generator,     \n",
    "    loss_func,\n",
    "    optimizer, \n",
    "    scheduler, \n",
    "    epochs, \n",
    "    device, \n",
    "    information:str, \n",
    "    show_train_process=None\n",
    "):\n",
    "    best_epoch = 0\n",
    "    best_test_loss = 9.9e9\n",
    "    best_net = net.state_dict()\n",
    "    sum_train_loss, sum_test_loss = [], []\n",
    "    date0 = time.strftime('%Y-%m-%d %a %H-%M-%S', time.localtime(time.time()))\n",
    "\n",
    "    with open(path.format(date=date0, information=information), 'w') as log_fin:\n",
    "        log_fin.write(information + '\\n')\n",
    "        log_fin.write('epoch' + ' ' + 'train_loss' + ' ' + 'test_loss' + ' ' + 'time' + ' ' + 'best_epoch' + '\\n')\n",
    "        t1 = time.time()\n",
    "        for epoch in range(epochs):\n",
    "            t0 = time.time()\n",
    "            train_loss = train(net, Train_generator, loss_func, optimizer, scheduler, device).item()\n",
    "            test_loss = evaluate(net, Test_generator, loss_func, optimizer, scheduler, device).item()\n",
    "\n",
    "            sum_train_loss.append(train_loss)\n",
    "            sum_test_loss.append(test_loss)\n",
    "\n",
    "            if epoch == 0 or test_loss < best_test_loss:\n",
    "                best_epoch = epoch\n",
    "                best_test_loss = test_loss\n",
    "                best_net = net.state_dict()\n",
    "\n",
    "            log_fin.write(str(epoch) + ' ' + str(train_loss) + ' ' + str(test_loss) + ' ' + str(time.time()-t0) + ' ' + str(best_epoch) + '\\n')\n",
    "            if show_train_process != None and epoch % show_train_process == 0:\n",
    "                print('epoch={:>4}, train_loss= {:.4f}, test_loss= {:.4f}, time= {:.2f}sec, best_epoch= {:>4}'.format(epoch, train_loss, test_loss, time.time()-t1, best_epoch))\n",
    "                t1 = time.time()\n",
    "        \n",
    "        log_fin.write('\\n')\n",
    "        log_fin.write('best_epoch=' + str(best_epoch) + '\\n')\n",
    "        log_fin.write('best_test_loss=' + str(best_test_loss) + '\\n')\n",
    "    return best_test_loss, best_epoch, best_net, sum_train_loss, sum_test_loss\n",
    "\n",
    "\n",
    "def singal_train_CNN(i, lr=LEARNING_RATE, ga=0.5, dropout=0.5):\n",
    "    t1 = time.time()\n",
    "    train_iter, test_iter = get_iter(PATH, BATCH_SIZE)\n",
    "    # test_iter = DataLoader([final_data, final_labels], batch_size=BATCH_SIZE, shuffle=True, pin_memory=False)\n",
    "    # criteon = nn.BCEWithLogitsLoss().to(DEVICE)\n",
    "    criteon = nn.MSELoss().to(DEVICE)\n",
    "    # net = CNN(1, TIME_LENGTH, INPUT_SIZE, 1, 32, [3, 5, 7, 9], dropout)\n",
    "    net = CNN(1,TIME_LENGTH//2, 18,TIME_LENGTH//2, 8, [9,7,5,3], dropout)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE, weight_decay=0)\n",
    "    scheduler = MultiStepLR(optimizer, [int(EPOCHS*0.2), int(EPOCHS*0.4)], ga, last_epoch=-1)\n",
    "\n",
    "    best_test_loss, best_epoch, _, multi_train_loss, multi_test_loss = train_multi_epochs(f'./output/{i}', net, train_iter, test_iter, criteon, optimizer, scheduler, EPOCHS, DEVICE, 'Temperature={}'.format(300), show_train_process=10)\n",
    "\n",
    "    print('best_test_loss= {:.4f}, best_epoch= {:>4}, time= {:.2f}sec'.format(best_test_loss, best_epoch, time.time()-t1))\n",
    "\n",
    "    plt.plot(multi_train_loss)\n",
    "    plt.plot(multi_test_loss)\n",
    "    plt.savefig(f'./output/{i}.png')\n",
    "    \n",
    "    return multi_train_loss, multi_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2aa2e134-76d6-4e12-a796-f29c6c5fb62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=   0, train_loss= 916201.8374, test_loss= 849042.3220, time= 1.63sec, best_epoch=    0\n",
      "epoch=  10, train_loss= 157656.4408, test_loss= 124256.9221, time= 15.88sec, best_epoch=   10\n",
      "epoch=  20, train_loss= 43405.1469, test_loss= 28510.7115, time= 15.92sec, best_epoch=   20\n",
      "epoch=  30, train_loss= 27583.0736, test_loss= 14565.3514, time= 15.99sec, best_epoch=   30\n",
      "epoch=  40, train_loss= 24671.9256, test_loss= 11229.5299, time= 15.91sec, best_epoch=   40\n",
      "epoch=  50, train_loss= 22839.5349, test_loss= 10001.9674, time= 15.96sec, best_epoch=   50\n",
      "epoch=  60, train_loss= 21531.1444, test_loss= 9247.7491, time= 16.00sec, best_epoch=   60\n",
      "epoch=  70, train_loss= 20494.9681, test_loss= 8802.4569, time= 15.98sec, best_epoch=   69\n",
      "epoch=  80, train_loss= 19850.0224, test_loss= 8248.2352, time= 15.89sec, best_epoch=   79\n",
      "epoch=  90, train_loss= 19898.1840, test_loss= 7737.9131, time= 15.93sec, best_epoch=   88\n",
      "epoch= 100, train_loss= 18012.0019, test_loss= 7105.1030, time= 15.89sec, best_epoch=  100\n",
      "epoch= 110, train_loss= 17357.7463, test_loss= 6653.5562, time= 16.03sec, best_epoch=  108\n",
      "epoch= 120, train_loss= 16627.3235, test_loss= 6089.2937, time= 15.87sec, best_epoch=  120\n",
      "epoch= 130, train_loss= 16315.6511, test_loss= 5579.0488, time= 15.82sec, best_epoch=  130\n",
      "epoch= 140, train_loss= 15130.4800, test_loss= 5083.3562, time= 15.89sec, best_epoch=  140\n",
      "epoch= 150, train_loss= 14774.4425, test_loss= 4525.0394, time= 16.00sec, best_epoch=  150\n",
      "epoch= 160, train_loss= 13348.8770, test_loss= 4146.4055, time= 15.91sec, best_epoch=  159\n",
      "epoch= 170, train_loss= 13622.3350, test_loss= 3783.9647, time= 15.91sec, best_epoch=  168\n",
      "epoch= 180, train_loss= 12708.2210, test_loss= 3160.7209, time= 15.96sec, best_epoch=  180\n",
      "epoch= 190, train_loss= 12094.4832, test_loss= 2714.9923, time= 15.94sec, best_epoch=  190\n",
      "epoch= 200, train_loss= 11045.7628, test_loss= 2388.1342, time= 15.96sec, best_epoch=  200\n",
      "epoch= 210, train_loss= 10864.7898, test_loss= 2113.6746, time= 15.88sec, best_epoch=  209\n",
      "epoch= 220, train_loss= 10372.1520, test_loss= 1867.7004, time= 15.85sec, best_epoch=  219\n",
      "epoch= 230, train_loss= 9102.0235, test_loss= 1495.2670, time= 15.92sec, best_epoch=  230\n",
      "epoch= 240, train_loss= 9106.5157, test_loss= 1254.6746, time= 15.89sec, best_epoch=  239\n",
      "epoch= 250, train_loss= 8862.5130, test_loss= 1116.2500, time= 15.95sec, best_epoch=  250\n",
      "epoch= 260, train_loss= 8529.7160, test_loss= 954.5158, time= 15.97sec, best_epoch=  260\n",
      "epoch= 270, train_loss= 8705.8748, test_loss= 904.9423, time= 15.91sec, best_epoch=  270\n",
      "epoch= 280, train_loss= 8267.0535, test_loss= 935.7285, time= 15.84sec, best_epoch=  277\n",
      "epoch= 290, train_loss= 7855.6451, test_loss= 719.3661, time= 15.95sec, best_epoch=  290\n",
      "epoch= 300, train_loss= 8023.9506, test_loss= 639.7240, time= 16.00sec, best_epoch=  298\n",
      "epoch= 310, train_loss= 7527.1975, test_loss= 647.2724, time= 15.88sec, best_epoch=  303\n",
      "epoch= 320, train_loss= 7761.0435, test_loss= 544.1616, time= 15.97sec, best_epoch=  319\n",
      "epoch= 330, train_loss= 7696.7697, test_loss= 516.7063, time= 15.90sec, best_epoch=  328\n",
      "epoch= 340, train_loss= 7192.8821, test_loss= 423.1741, time= 15.86sec, best_epoch=  340\n",
      "epoch= 350, train_loss= 6897.3431, test_loss= 453.0874, time= 15.92sec, best_epoch=  349\n",
      "epoch= 360, train_loss= 7273.3401, test_loss= 391.3356, time= 15.89sec, best_epoch=  359\n",
      "epoch= 370, train_loss= 7102.5919, test_loss= 398.3919, time= 15.80sec, best_epoch=  359\n",
      "epoch= 380, train_loss= 6618.6276, test_loss= 340.7507, time= 15.85sec, best_epoch=  379\n",
      "epoch= 390, train_loss= 6667.8935, test_loss= 323.6603, time= 15.89sec, best_epoch=  389\n",
      "best_test_loss= 260.8147, best_epoch=  397, time= 650.70sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "multi_train_loss, multi_test_loss = singal_train_CNN(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dbcdf2-8735-4a6c-86c2-beca76d71a70",
   "metadata": {},
   "source": [
    "# 需要研究下X Y是不是有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f7649e-1b0a-4083-bfaa-4d1517e4211a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
